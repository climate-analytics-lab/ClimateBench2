{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db423239",
   "metadata": {},
   "source": [
    "# make annual maps for each period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/willatobin/Documents/SIO/ClimateBench2/backend/paleo_data_cache'\n",
    "# eocene\n",
    "eocene_models = glob.glob(f'{root_path}/deepmip/dap.ceda.ac.uk/badc/cmip6/data/CMIP6Plus/DeepMIP/deepmip-eocene-p1/*/*/*-x*/*/climatology/*')\n",
    "\n",
    "# pliocene\n",
    "pliocene_models = glob.glob(f'{root_path}/*/midPliocene-eoi400_tas_annual.nc')\n",
    "# lig127k\n",
    "lig127k_models = glob.glob(f'{root_path}/*/lig127k_tas_annual.nc')\n",
    "# LGM\n",
    "lgm_models = glob.glob(f'{root_path}/*/lgm_tas_annual.nc')\n",
    "# midH\n",
    "midHolocene_models = glob.glob(f'{root_path}/*/midHolocene_tas_annual.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# period = 'eocene'\n",
    "# for file in eocene_models:\n",
    "#     model = file.split('/')[17]\n",
    "#     co2 = file.split('/')[18].split('-')[-1]\n",
    "\n",
    "#     ds = xr.open_dataset(file)\n",
    "    \n",
    "#     if \"t\" in ds.dims:\n",
    "#         ds = ds.rename({'t':'time','latitude':'lat','longitude':'lon'})\n",
    "#     if \"time_counter\" in ds.dims:\n",
    "#         ds = ds.rename({'time_counter':'time'})\n",
    "    \n",
    "#     ds = ds.mean(dim='time')\n",
    "\n",
    "#     fig, axis = plt.subplots(1, 1, figsize=(9,5),subplot_kw=dict(projection=ccrs.Robinson(central_longitude=180)))\n",
    "\n",
    "#     cax = (ds['tas'] - 273.15).plot(\n",
    "#         ax=axis,transform=ccrs.PlateCarree(), \n",
    "#         vmin = -60,\n",
    "#         vmax = 60,\n",
    "#         cmap = 'RdBu_r',\n",
    "#         add_colorbar=False\n",
    "#     )\n",
    "#     cbar = fig.colorbar(cax, ticks=[-60,-30, 0, 30,60])\n",
    "#     axis.coastlines()  # cartopy function\n",
    "\n",
    "#     axis.set_title(f\"{model} CO2{co2}\",fontsize=20)\n",
    "\n",
    "#     os.makedirs(f'results/paleo/{period}_maps',exist_ok=True)\n",
    "#     fig.savefig(f'results/paleo/{period}_maps/{model}_{float(co2[1:])}.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8478718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# period = 'pliocene' # run this for each non eocene period\n",
    "# for file in pliocene_models:\n",
    "#     model = file.split('/')[8]\n",
    "\n",
    "#     ds = xr.open_dataset(file)\n",
    "\n",
    "#     fig, axis = plt.subplots(1, 1, figsize=(9,5),subplot_kw=dict(projection=ccrs.Robinson(central_longitude=180)))\n",
    "\n",
    "#     cax = (ds['tas'] - 273.15).plot(\n",
    "#         ax=axis,transform=ccrs.PlateCarree(), \n",
    "#         vmin = -60,\n",
    "#         vmax = 60,\n",
    "#         cmap = 'RdBu_r',\n",
    "#         add_colorbar=False\n",
    "#     )\n",
    "#     cbar = fig.colorbar(cax, ticks=[-60,-30, 0, 30,60])\n",
    "#     axis.coastlines()  # cartopy function\n",
    "\n",
    "#     axis.set_title(model,fontsize=20)\n",
    "\n",
    "#     os.makedirs(f'results/paleo/{period}_maps',exist_ok=True)\n",
    "#     fig.savefig(f'results/paleo/{period}_maps/{model}.png', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2797a",
   "metadata": {},
   "source": [
    "for seasonal plots, do zonal means and make csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://cmip6.storage.googleapis.com/pangeo-cmip6.csv\")\n",
    "piC_tas_df = df[(df['activity_id'] == 'CMIP') & (df['experiment_id'] == 'piControl')& (df['table_id'] == 'Amon')& (df['variable_id'] == 'tas')]#['table_id'].unique()\n",
    "\n",
    "piC_eocene = glob.glob(f'{root_path}/deepmip/dap.ceda.ac.uk/badc/cmip6/data/CMIP6Plus/DeepMIP/deepmip-eocene-p1/*/*/*-PI/*/climatology/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ef903",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MONTHLY AVERAGES FOR EVERY MODEL AND TIME PERIOD ####\n",
    "regions = {\n",
    "    'global':[-90,90],\n",
    "    'northern_hemisphere':[0,90],\n",
    "    'tropics':[-30,30],\n",
    "    'southern_hemisphere':[-90,0],\n",
    "}\n",
    "\n",
    "monthly_files = glob.glob(f'{root_path}/*/*_tas_monthly.nc')\n",
    "_results = []\n",
    "\n",
    "for region, bnds in regions.items():\n",
    "    for file in monthly_files:\n",
    "        model = file.split('/')[8]\n",
    "        period = file.split('/')[9].split('_')[0]\n",
    "\n",
    "        ds = xr.open_dataset(file)\n",
    "    \n",
    "        ds_slice = ds.sel(lat = slice(bnds[0],bnds[1]))\n",
    "        ds_zmean = ds_slice['tas'].weighted(ds_slice['weight'].fillna(0)).mean(dim=['lat','lon'])\n",
    "\n",
    "        # get pi control to calculate anomaly\n",
    "        piC_ds = xr.open_zarr(piC_tas_df[piC_tas_df['source_id'] == model].iloc[0]['zstore'],chunks={})\n",
    "        piC_zmean = piC_ds.sel(lat = slice(bnds[0],bnds[1]))['tas'].weighted(ds_slice['weight'].fillna(0)).mean(dim=['lat','lon'])\n",
    "        piC_zmean = piC_zmean.groupby('time.month').mean()\n",
    "        \n",
    "        df_zmean = ds_zmean.to_dataframe().reset_index()\n",
    "        df_zmean = df_zmean.merge(piC_zmean.to_dataframe().reset_index()[['month','tas']].rename(columns={'tas':'tas_pi'}),on='month')\n",
    "\n",
    "        df_zmean['model'] = model\n",
    "        df_zmean['period'] = period\n",
    "        df_zmean['region'] = region\n",
    "        df_zmean['co2_exp'] = np.nan\n",
    "        _results.append(df_zmean)\n",
    "\n",
    "    for file in eocene_models:\n",
    "        model = file.split('/')[17]\n",
    "        co2 = file.split('/')[18].split('-')[-1]\n",
    "        pi_file = [x for x in piC_eocene if model in x]\n",
    "\n",
    "        ds = xr.open_dataset(file)\n",
    "        ds_pi = xr.open_dataset(pi_file[0])\n",
    "        \n",
    "        if \"t\" in ds.dims:\n",
    "            ds = ds.rename({'t':'time','latitude':'lat','longitude':'lon'})\n",
    "            ds_pi = ds_pi.rename({'t':'time','latitude':'lat','longitude':'lon'})\n",
    "        if \"time_counter\" in ds.dims:\n",
    "            ds = ds.rename({'time_counter':'time'})\n",
    "            ds_pi = ds_pi.rename({'time_counter':'time'})\n",
    "\n",
    "        ds = ds.sortby('lat')\n",
    "        ds_pi = ds_pi.sortby('lat')\n",
    "        \n",
    "        ds = ds.groupby('time.month').mean()\n",
    "        ds_pi = ds_pi.groupby('time.month').mean()\n",
    "\n",
    "        ds_slice = ds.sel(lat = slice(bnds[0],bnds[1]))\n",
    "        ds_pi_slice = ds_pi.sel(lat = slice(bnds[0],bnds[1]))\n",
    "\n",
    "        weights = np.cos(np.deg2rad(ds_slice.lat))\n",
    "        weights = weights.expand_dims({\"lon\": ds_slice.lon})\n",
    "\n",
    "        ds_zmean = ds_slice['tas'].weighted(weights.fillna(0)).mean(dim=['lat','lon'])\n",
    "        ds_pi_zmean = ds_pi_slice['tas'].weighted(weights.fillna(0)).mean(dim=['lat','lon'])\n",
    "\n",
    "        df_zmean = ds_zmean.to_dataframe().reset_index()\n",
    "        df_zmean = df_zmean.merge(ds_pi_zmean.to_dataframe().reset_index()[['month','tas']].rename(columns={'tas':'tas_pi'}),on='month')\n",
    "\n",
    "        df_zmean['model'] = model\n",
    "        df_zmean['period'] = 'eocene'\n",
    "        df_zmean['region'] = region\n",
    "        df_zmean['co2_exp'] = co2\n",
    "        _results.append(df_zmean)\n",
    "\n",
    "seasonal_paleo_results = pd.concat(_results)\n",
    "# seasonal_paleo_results[(seasonal_paleo_results['period'] == 'lig127k') & (seasonal_paleo_results['region'] == 'global')].pivot_table(index='month',columns='model',values = 'tas').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_paleo_results['co2_exp'] = seasonal_paleo_results['co2_exp'].str[1:].astype(float)\n",
    "\n",
    "seasonal_paleo_results['tas_anom'] = seasonal_paleo_results['tas'] - seasonal_paleo_results['tas_pi']\n",
    "seasonal_paleo_results['tas'] = seasonal_paleo_results['tas'] - 273.15\n",
    "seasonal_paleo_results['tas_pi'] = seasonal_paleo_results['tas_pi'] - 273.15\n",
    "\n",
    "seasonal_obs = pd.read_csv('observational_data/paleo/processed/monthly_mean_zonal_obs.csv').drop(columns=['Unnamed: 0'])\n",
    "seasonal_obs = seasonal_obs[['month','period','region','tas_anom','error']].rename(columns={'tas_anom':'tas_obs'})\n",
    "monthly_zonal_means = seasonal_paleo_results.merge(seasonal_obs,on=['month','period','region'],how='outer')\n",
    "monthly_zonal_means['mae'] = (monthly_zonal_means['tas_anom'] - monthly_zonal_means['tas_obs']).abs()\n",
    "monthly_zonal_means.drop(columns=['height']).to_csv('results/paleo/monthly_zonal_means.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c681aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANNUAL AVERAGES FOR EVERY MODEL AND TIME PERIOD ####\n",
    "\n",
    "df = pd.read_csv(\"https://cmip6.storage.googleapis.com/pangeo-cmip6.csv\")\n",
    "piC_tas_df = df[(df['activity_id'] == 'CMIP') & (df['experiment_id'] == 'piControl')& (df['table_id'] == 'Amon')& (df['variable_id'] == 'tas')]#['table_id'].unique()\n",
    "\n",
    "annual_files = glob.glob(f'{root_path}/*/*_tas_annual.nc')\n",
    "_results = []\n",
    "\n",
    "for file in annual_files:\n",
    "    model = file.split('/')[8]\n",
    "    period = file.split('/')[9].split('_')[0]\n",
    "\n",
    "    ds = xr.open_dataset(file)\n",
    "\n",
    "    # get pi control to calculate anomaly\n",
    "    piC_ds = xr.open_zarr(piC_tas_df[piC_tas_df['source_id'] == model].iloc[0]['zstore'],chunks={})\n",
    "    ds_anom = ds - piC_ds.mean(dim='time').drop_vars(['height','lat_bnds','lon_bnds','time_bnds'],errors='ignore')\n",
    "\n",
    "    ds_zmean = ds_anom['tas'].weighted(ds['weight'].fillna(0)).mean(dim=['lat','lon'])\n",
    "\n",
    "    df_zmean = pd.DataFrame({\n",
    "        'tas':[ds_zmean.values.tolist()],\n",
    "        'model':[model],\n",
    "        'period':[period],\n",
    "        'region':['global'],\n",
    "    })\n",
    "    _results.append(df_zmean)\n",
    "\n",
    "annual_paleo_results = pd.concat(_results)\n",
    "\n",
    "annual_paleo_results['period_idx'] = 1\n",
    "annual_paleo_results.loc[annual_paleo_results['period'] == 'lig127k','period_idx'] = 2\n",
    "annual_paleo_results.loc[annual_paleo_results['period'] == 'lgm','period_idx'] = 3\n",
    "annual_paleo_results.loc[annual_paleo_results['period'] == 'midHolocene','period_idx'] = 4\n",
    "\n",
    "\n",
    "# get eocene annual results\n",
    "eeco_files = glob.glob('/Users/willatobin/Documents/SIO/ClimateBench2/backend/paleo_data_cache/deepmip/dap.ceda.ac.uk/badc/cmip6/data/CMIP6Plus/DeepMIP/deepmip-eocene-p1/*/*/*/*/*/*')\n",
    "\n",
    "eeco_models_df = pd.concat([\n",
    "    pd.DataFrame(eeco_files).rename(columns={0:'local_path'}),\n",
    "    pd.DataFrame(eeco_files)[0].str.split('/',expand=True)[[17,18]].rename(columns={17:'model',18:'experiment'})\n",
    "],axis=1)\n",
    "\n",
    "eeco_models_df['experiment_id'] = eeco_models_df['experiment'].str[-1]\n",
    "eeco_models_df.loc[eeco_models_df['experiment_id'] == 'I','experiment_id'] = 0\n",
    "eeco_models_df['experiment_id'] = eeco_models_df['experiment_id'].astype(int)\n",
    "\n",
    "eeco_exp_models = eeco_models_df[~(eeco_models_df['experiment_id'] == 0)]  \n",
    "\n",
    "_results = []\n",
    "for row in eeco_exp_models.itertuples(index=False):\n",
    "    model = row.model\n",
    "    eeco_path = row.local_path\n",
    "    pi_path = eeco_models_df[(eeco_models_df['model'] == model) & (eeco_models_df['experiment_id'] == 0)].iloc[0]['local_path']\n",
    "\n",
    "    ds_piC = xr.open_dataset(pi_path,chunks={},decode_times=False)\n",
    "    ds_eeco = xr.open_dataset(eeco_path,chunks={},decode_times=False)\n",
    "\n",
    "\n",
    "    if \"t\" in ds_piC.dims:\n",
    "        ds_piC = ds_piC.rename({'t':'time','latitude':'lat','longitude':'lon'})\n",
    "        ds_eeco = ds_eeco.rename({'t':'time','latitude':'lat','longitude':'lon'})\n",
    "    if \"time_counter\" in ds_piC.dims:\n",
    "        ds_piC = ds_piC.rename({'time_counter':'time'})\n",
    "        ds_eeco = ds_eeco.rename({'time_counter':'time'})\n",
    "\n",
    "    ds_piC = ds_piC.mean(dim='time').drop_vars(['height','lat_bnds','lon_bnds'],errors='ignore')\n",
    "    ds_eeco = ds_eeco.mean(dim='time').drop_vars(['height','lat_bnds','lon_bnds'],errors='ignore')\n",
    "\n",
    "    ds_anom = ds_eeco - ds_piC\n",
    "\n",
    "    weights = np.cos(np.deg2rad(ds_anom.lat))\n",
    "    weights = weights.expand_dims({\"lon\": ds_anom.lon})\n",
    "    weights.name = 'areacella'\n",
    "\n",
    "    zmean = ds_anom.weighted(weights.fillna(0)).mean().compute()\n",
    "\n",
    "    df_zmean = pd.DataFrame({\n",
    "        'tas':[zmean['tas'].values.tolist()],\n",
    "        'model':[model],\n",
    "        'period':['eocene'],\n",
    "        'region':['global'],\n",
    "        'co2_exp':[row.experiment_id],\n",
    "    })\n",
    "    _results.append(df_zmean)\n",
    "annual_eocene_results = pd.concat(_results)\n",
    "annual_eocene_results['period_idx'] = 0\n",
    "\n",
    "annual_paleo_results = pd.concat([\n",
    "    annual_eocene_results,\n",
    "    annual_paleo_results\n",
    "])\n",
    "annual_paleo_results = annual_paleo_results.rename(columns={'tas':'tas_anom'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicate IPCC fig 7.19\n",
    "paleo_sat_avgs = pd.read_csv('observational_data/paleo/processed/annual_mean_global_obs.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.errorbar(np.arange(1,6), paleo_sat_avgs['tas_anom'], yerr=paleo_sat_avgs['error'], fmt='o',label='Observations')\n",
    "plt.scatter(x=annual_paleo_results['period_idx'] + 1.2,y=annual_paleo_results['tas_anom'],label='Models',color='orange')\n",
    "\n",
    "ax.set_xticks(np.arange(1,6))\n",
    "ax.set_xticklabels(paleo_sat_avgs['period'],rotation=45);\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae_results = annual_paleo_results.merge(paleo_sat_avgs[['period','tas_anom']].rename(columns={'tas_anom':'tas_obs'}))\n",
    "mae_results['mae'] = (mae_results['tas_anom'] - mae_results['tas_obs']).abs()\n",
    "# add normalized MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eocene_median_mae = mae_results[['period','co2_exp','mae']].groupby(['period','co2_exp']).median().reset_index().rename(columns={'mae':'median_mae'})\n",
    "\n",
    "non_eocene_median_mae = mae_results[['period','mae']].groupby('period').median().reset_index().rename(columns={'mae':'median_mae'})\n",
    "non_eocene_median_mae = non_eocene_median_mae[non_eocene_median_mae['period'] != 'eocene']\n",
    "non_eocene_median_mae['co2_exp'] = np.nan\n",
    "\n",
    "mae_results = mae_results.merge(\n",
    "    pd.concat([eocene_median_mae,non_eocene_median_mae]),\n",
    "    on=['period','co2_exp'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "mae_results['nmae'] = mae_results['mae'] / mae_results['median_mae']\n",
    "\n",
    "mae_results.to_csv('/Users/willatobin/Documents/SIO/ClimateBench2/backend/results/paleo/annual_zonal_means.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfe586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
